{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T02:45:22.318577Z",
     "start_time": "2025-05-15T02:45:22.180013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from os import listdir\n",
    "\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from kagglehub import dataset_download\n",
    "from keras import Model, Input\n",
    "from keras.src.applications.inception_v3 import InceptionV3\n",
    "from keras.src.layers import GlobalAveragePooling2D, Dense, Conv2D, AveragePooling2D, Flatten, Dropout\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "from keras.src.utils import to_categorical\n",
    "from matplotlib import pyplot\n",
    "from numpy import zeros, asarray, argmax, array\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "# noinspection PyUnresolvedReferences\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import load_img, image_dataset_from_directory\n",
    "from tensorflow.python.keras.layers import MaxPool2D"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MaxPool2D' from 'keras.src.layers' (D:\\Dev\\my_ai_journey\\deep-learning\\inception-network\\.venv\\Lib\\site-packages\\keras\\src\\layers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 8\u001B[39m\n\u001B[32m      6\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mkeras\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Model\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mkeras\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msrc\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mapplications\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01minception_v3\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m InceptionV3\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mkeras\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msrc\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlayers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m GlobalAveragePooling2D, Dense, Conv2D, MaxPool2D\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mkeras\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msrc\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlegacy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mpreprocessing\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mimage\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ImageDataGenerator\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mkeras\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msrc\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m to_categorical\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'MaxPool2D' from 'keras.src.layers' (D:\\Dev\\my_ai_journey\\deep-learning\\inception-network\\.venv\\Lib\\site-packages\\keras\\src\\layers\\__init__.py)"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\moham\\.cache\\kagglehub\\datasets\\abhinavnayak\\catsvdogs-transformed\\versions\\1\n"
     ]
    }
   ],
   "execution_count": 7,
   "source": [
    "dataset_path = dataset_download(\"abhinavnayak/catsvdogs-transformed\")\n",
    "print(\"Path to dataset files:\", dataset_path)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T02:14:50.873270Z",
     "start_time": "2025-05-15T02:14:50.867265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_path: str = f\"{dataset_path}/train_transformed/\"\n",
    "print(data_path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\.cache\\kagglehub\\datasets\\abhinavnayak\\catsvdogs-transformed\\versions\\1/train_transformed/\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T02:14:51.184434Z",
     "start_time": "2025-05-15T02:14:51.176168Z"
    }
   },
   "cell_type": "code",
   "source": "list_of_images = listdir(data_path)",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T02:14:51.282177Z",
     "start_time": "2025-05-15T02:14:51.275217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "number_of_images: int = len(list_of_images)\n",
    "print(number_of_images)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "i = 1\n",
    "pyplot.figure(figsize=(10, 10))\n",
    "for image in list_of_images:\n",
    "    if i > 5:\n",
    "        break\n",
    "    img = load_img(data_path + image)\n",
    "    pyplot.subplot(1, 5, i)\n",
    "    pyplot.imshow(img)\n",
    "    pyplot.title(str(img.size))\n",
    "    pyplot.axis('off')\n",
    "    i += 1\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "images = zeros((number_of_images, 224, 224, 3))\n",
    "labels = zeros((number_of_images, 1))"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for image_number, image_path in enumerate(list_of_images):\n",
    "    img = Image.open(data_path + image_path)\n",
    "    img = asarray(img)\n",
    "    img = img / img.max()\n",
    "    images[image_number] = img\n",
    "    labels[image_number] = 0 if \"cat\" in image_path else 1"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(labels)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "labels = to_categorical(labels)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print(labels)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "images.shape"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pyplot.imshow(images[0])"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "x_train, x_test = x_train / 255.0, x_test / 255.0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = InceptionV3(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224, 224, 3),\n",
    ")\n",
    "\n",
    "# Freeze the pre-trained layers\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add layers using calls:\n",
    "x = model.output  # Get the output of the InceptionV3 base\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "predictions = Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "# Create a new Functional model with these layers:\n",
    "model = Model(inputs=model.input, outputs=predictions)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "history = model.fit(x_train, y_train, epochs=50)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pyplot.plot(history.history[\"accuracy\"])\n",
    "pyplot.plot(history.history[\"loss\"])\n",
    "pyplot.title(\"Model Accuracy\")\n",
    "pyplot.ylabel(\"Accuracy\")\n",
    "pyplot.xlabel(\"Epoch\")\n",
    "pyplot.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.evaluate(x_test, y_test)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_predict = model.predict(x_test)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y_predict = argmax(y_predict, axis=1)\n",
    "y_test = argmax(y_test, axis=1)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cm = confusion_matrix(y_test, y_predict)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cr = classification_report(y_test, y_predict)\n",
    "print(cr)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model From Scratch"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,  # Degree range for random rotations\n",
    "    width_shift_range=0.2,  # Fraction of the total width for horizontal shifts\n",
    "    height_shift_range=0.2,  # Fraction of total height for vertical shifts\n",
    "    shear_range=0.2,  # Shear intensity (shear angle in a counter-clockwise direction in degrees)\n",
    "    zoom_range=0.2,  # Range for random zoom\n",
    "    horizontal_flip=True,  # Randomly flip images horizontally\n",
    "    fill_mode='nearest'  # Strategy for filling newly created pixels\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow(\n",
    "    images, labels, batch_size=32\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_generator"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "images = array(images)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "images.shape"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from keras.src.layers import concatenate\n",
    "\n",
    "\n",
    "def inception_module(X, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5,\n",
    "                     filters_pool_proj, name=None):\n",
    "    conv_1x1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu')(X)\n",
    "\n",
    "    conv_3x3 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(X)\n",
    "    conv_3x3 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu')(conv_3x3)\n",
    "\n",
    "    conv_5x5 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(X)\n",
    "    conv_5x5 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu')(conv_5x5)\n",
    "\n",
    "    pool_proj = MaxPool2D((3, 3), strides=(1, 1), padding='same')(X)\n",
    "    pool_proj = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu')(pool_proj)\n",
    "\n",
    "    output = concatenate([conv_1x1, conv_3x3, conv_5x5, pool_proj], axis=3, name=name)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "input_layer = Input(shape=(224, 224, 3))\n",
    "\n",
    "x = Conv2D(64, (7, 7), padding='same', strides=(2, 2), activation='relu', name='conv_1_7x7/2')(\n",
    "    input_layer)\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_1_3x3/2')(x)\n",
    "x = Conv2D(64, (1, 1), padding='same', strides=(1, 1), activation='relu', name='conv_2a_3x3/1')(x)\n",
    "x = Conv2D(192, (3, 3), padding='same', strides=(1, 1), activation='relu', name='conv_2b_3x3/1')(x)\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_2_3x3/2')(x)\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=64,\n",
    "                     filters_3x3_reduce=96,\n",
    "                     filters_3x3=128,\n",
    "                     filters_5x5_reduce=16,\n",
    "                     filters_5x5=32,\n",
    "                     filters_pool_proj=32,\n",
    "                     name='inception_3a')\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=128,\n",
    "                     filters_3x3_reduce=128,\n",
    "                     filters_3x3=192,\n",
    "                     filters_5x5_reduce=32,\n",
    "                     filters_5x5=96,\n",
    "                     filters_pool_proj=64,\n",
    "                     name='inception_3b')\n",
    "\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_3_3x3/2')(x)\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=192,\n",
    "                     filters_3x3_reduce=96,\n",
    "                     filters_3x3=208,\n",
    "                     filters_5x5_reduce=16,\n",
    "                     filters_5x5=48,\n",
    "                     filters_pool_proj=64,\n",
    "                     name='inception_4a')\n",
    "\n",
    "x1 = AveragePooling2D((5, 5), strides=3)(x)\n",
    "x1 = Conv2D(128, (1, 1), padding='same', activation='relu')(x1)\n",
    "x1 = Flatten()(x1)\n",
    "x1 = Dense(1024, activation='relu')(x1)\n",
    "x1 = Dropout(0.7)(x1)\n",
    "x1 = Dense(2, activation='softmax', name='auxiliary_output_1')(x1)\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=160,\n",
    "                     filters_3x3_reduce=112,\n",
    "                     filters_3x3=224,\n",
    "                     filters_5x5_reduce=24,\n",
    "                     filters_5x5=64,\n",
    "                     filters_pool_proj=64,\n",
    "                     name='inception_4b')\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=128,\n",
    "                     filters_3x3_reduce=128,\n",
    "                     filters_3x3=256,\n",
    "                     filters_5x5_reduce=24,\n",
    "                     filters_5x5=64,\n",
    "                     filters_pool_proj=64,\n",
    "                     name='inception_4c')\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=112,\n",
    "                     filters_3x3_reduce=144,\n",
    "                     filters_3x3=288,\n",
    "                     filters_5x5_reduce=32,\n",
    "                     filters_5x5=64,\n",
    "                     filters_pool_proj=64,\n",
    "                     name='inception_4d')\n",
    "\n",
    "x2 = AveragePooling2D((5, 5), strides=3)(x)\n",
    "x2 = Conv2D(128, (1, 1), padding='same', activation='relu')(x2)\n",
    "x2 = Flatten()(x2)\n",
    "x2 = Dense(1024, activation='relu')(x2)\n",
    "x2 = Dropout(0.7)(x2)\n",
    "x2 = Dense(2, activation='softmax', name='auxiliary_output_2')(x2)\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=256,\n",
    "                     filters_3x3_reduce=160,\n",
    "                     filters_3x3=320,\n",
    "                     filters_5x5_reduce=32,\n",
    "                     filters_5x5=128,\n",
    "                     filters_pool_proj=128,\n",
    "                     name='inception_4e')\n",
    "\n",
    "x = MaxPool2D((3, 3), padding='same', strides=(2, 2), name='max_pool_4_3x3/2')(x)\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=256,\n",
    "                     filters_3x3_reduce=160,\n",
    "                     filters_3x3=320,\n",
    "                     filters_5x5_reduce=32,\n",
    "                     filters_5x5=128,\n",
    "                     filters_pool_proj=128,\n",
    "                     name='inception_5a')\n",
    "\n",
    "x = inception_module(x,\n",
    "                     filters_1x1=384,\n",
    "                     filters_3x3_reduce=192,\n",
    "                     filters_3x3=384,\n",
    "                     filters_5x5_reduce=48,\n",
    "                     filters_5x5=128,\n",
    "                     filters_pool_proj=128,\n",
    "                     name='inception_5b')\n",
    "\n",
    "x = GlobalAveragePooling2D(name='avg_pool_5_3x3/1')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(2, activation='softmax', name='output')(x)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model = Model(input_layer, [x, x1, x2], name='inception_v1')"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_train.shape"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "history = model.fit(train_generator, epochs=50)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pyplot.plot(history.history[\"loss\"])\n",
    "pyplot.title(\"Model Loss/Accuracy\")\n",
    "pyplot.ylabel(\"Loss/Accuracy\")\n",
    "pyplot.xlabel(\"Epoch\")\n",
    "pyplot.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_test = to_categorical(y_test)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_test.shape"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_test = argmax(y_test, axis=1)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.evaluate(x_test, y_test)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "x_test.shape, y_test.shape"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_predict = model.predict(x_test)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_predict = array(y_predict)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_predict[0].shape"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_predict = argmax(y_predict[0], axis=1)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_test.shape, y_predict.shape"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cm = confusion_matrix(y_test, y_predict)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cr = classification_report(y_test, y_predict)\n",
    "print(cr)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 111880,
     "sourceId": 269359,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

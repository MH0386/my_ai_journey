{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "<a href=\"https://www.kaggle.com/code/mh0386/logistic-regression-from-scratch?scriptVersionId=241976657\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from sys import float_info\n",
    "from typing import Literal, Callable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from cv2 import flip, getRotationMatrix2D, resize, warpAffine\n",
    "from kagglehub import dataset_download\n",
    "from numpy import float64, uint, array\n",
    "from numpy.typing import NDArray\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33439df9",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd73cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path: str = dataset_download(handle=\"rashikrahmanpritom/covid-wwo-pneumonia-chest-xray\")\n",
    "\n",
    "covid_without_PNEUMONIA_train_path = Path(f\"{path}/Data/train/covid_without_PNEUMONIA\")\n",
    "covid_with_PNEUMONIA_train_path = Path(f\"{path}/Data/train/covid_with_PNEUMONIA\")\n",
    "\n",
    "covid_without_PNEUMONIA_test_path = Path(f\"{path}/Data/test/covid_without_PNEUMONIA\")\n",
    "covid_with_PNEUMONIA_test_path = Path(f\"{path}/Data/test/covid_with_PNEUMONIA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6f3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_without_PNEUMONIA_path: list[Path] = [\n",
    "    covid_without_PNEUMONIA_train_path,\n",
    "    covid_without_PNEUMONIA_test_path,\n",
    "]\n",
    "\n",
    "covid_with_PNEUMONIA_path: list[Path] = [\n",
    "    covid_with_PNEUMONIA_train_path,\n",
    "    covid_with_PNEUMONIA_test_path,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28268180",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d5315",
   "metadata": {},
   "outputs": [],
   "source": [
    "label2category: dict[str, int] = {\n",
    "    \"covid_without_PNEUMONIA\": 0,\n",
    "    \"covid_with_PNEUMONIA\": 1,\n",
    "}\n",
    "category2label: dict[int, str] = {\n",
    "    0: \"covid_without_PNEUMONIA\",\n",
    "    1: \"covid_with_PNEUMONIA\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409e7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "data: list[dict[str, str]] = []\n",
    "\n",
    "for path in covid_without_PNEUMONIA_path:\n",
    "    for img in path.glob(pattern=\"*.jpeg\"):\n",
    "        data.append({\"img_path\": str(object=img), \"label\": \"covid_without_PNEUMONIA\"})\n",
    "\n",
    "for path in covid_with_PNEUMONIA_path:\n",
    "    for img in path.glob(pattern=\"*.jpeg\"):\n",
    "        data.append({\"img_path\": str(object=img), \"label\": \"covid_with_PNEUMONIA\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f05c949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter_label(data: list[dict[str, str]], key: str) -> Counter[str]:\n",
    "    return Counter([record[key] for record in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac962edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_l_counter: Counter[str] = counter_label(data=data, key=\"label\")\n",
    "\n",
    "keys = list(img_l_counter.keys())\n",
    "values = list(img_l_counter.values())\n",
    "\n",
    "plt.bar(x=keys, height=values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3545d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "\n",
    "for i, data_ in enumerate(iterable=data[:10]):\n",
    "    path: str = data_[\"img_path\"]\n",
    "    label: str = data_[\"label\"]\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    img: NDArray[uint] = plt.imread(fname=path)\n",
    "    plt.imshow(X=img)\n",
    "    plt.xlabel(xlabel=label)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6af26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotating(\n",
    "    image: NDArray[float64],\n",
    "    angle: int = 90,\n",
    "    scale: float = 1.0,\n",
    ") -> NDArray[float64]:\n",
    "    # Get the dimensions of the image\n",
    "    h: int = image.shape[:2][0]\n",
    "    w: int = image.shape[:2][1]\n",
    "    # Compute the center of the image\n",
    "    center: tuple[float, float] = (w / 2.0, h / 2.0)\n",
    "    # Perform the rotation\n",
    "    M: NDArray[float64] = array(\n",
    "        object=getRotationMatrix2D(center=center, angle=angle, scale=scale),\n",
    "        dtype=float64,\n",
    "    )\n",
    "    rotated: NDArray[float64] = array(\n",
    "        object=warpAffine(src=image, M=M, dsize=(w, h)), dtype=float64\n",
    "    )\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dbb759",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fliping(image: NDArray[float64], flip_code: int) -> NDArray[float64]:\n",
    "    # Flip the image horizontally, vertically, or both\n",
    "    # flip_code = 0: flip vertically\n",
    "    # flip_code > 0: flip horizontally\n",
    "    # flip_code < 0: flip vertically and horizontally\n",
    "    return array(object=flip(src=image, flipCode=flip_code), dtype=float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b96f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resizing(image: NDArray[float64], size: tuple[int, int]) -> NDArray[float64]:\n",
    "    return array(object=resize(src=image, dsize=size), dtype=float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c946b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_array: list[NDArray[float64]] = []\n",
    "images_label: list[str] = []\n",
    "IMG_SIZE: tuple[Literal[100], Literal[100]] = (100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c2be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "for data_ in data:\n",
    "    category: int = label2category[data_[\"label\"]]\n",
    "    img: NDArray[float64] = plt.imread(fname=data_[\"img_path\"])\n",
    "    if category == 0:\n",
    "        random_angle: int = np.random.choice(a=[90, 180, 270])\n",
    "        random_flip: int = np.random.choice(a=[-1, 0, 1])\n",
    "        for i in range(2):\n",
    "            img_rotate: NDArray[float64] = rotating(image=img, angle=random_angle)\n",
    "            img_flip: NDArray[float64] = fliping(\n",
    "                image=img_rotate, flip_code=random_flip\n",
    "            )\n",
    "            img_resize: NDArray[float64] = resizing(image=img_flip, size=IMG_SIZE)\n",
    "            images_array.append(img_resize)\n",
    "            images_label.append(data_[\"label\"])\n",
    "    else:\n",
    "        img_resize: NDArray[float64] = resizing(image=img, size=IMG_SIZE)\n",
    "        images_array.append(img_resize)\n",
    "        images_label.append(data_[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a61de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot number of samples in each class\n",
    "# Assuming 'data' is your numpy array with class labels\n",
    "\n",
    "unique_elements = np.unique(ar=images_label, return_counts=True)\n",
    "classes = unique_elements[0]\n",
    "counts = unique_elements[1]\n",
    "\n",
    "print(f\"Classes: {classes}\")\n",
    "print(f\"Counts: {counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffb8896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the bar graph\n",
    "plt.bar(x=classes, height=counts)\n",
    "plt.xlabel(xlabel=\"Class\")\n",
    "plt.ylabel(ylabel=\"Number of samples\")\n",
    "plt.title(label=\"Number of samples in each class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b888a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_array: NDArray[float64] = np.array(object=images_array)\n",
    "images_label: NDArray = np.array(object=images_label)\n",
    "\n",
    "print(f\"shape of images array: {images_array.shape}, dtype: {images_array.dtype}\")\n",
    "print(f\"shape of images label: {images_label.shape}, dtype: {images_label.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115227fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "\n",
    "for i, data_ in enumerate(iterable=images_array[:10]):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X=data_.astype(uint))\n",
    "    plt.xlabel(xlabel=images_label[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fdd199",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_label: NDArray[uint] = np.where(images_label == \"covid_without_PNEUMONIA\", 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2d0490",
   "metadata": {},
   "source": [
    "# Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e5208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_centroid(block: NDArray[float64]) -> tuple[float64, float64, float64]:\n",
    "    \"\"\"Calculate the centroid of a 3D matrix\"\"\"\n",
    "    rows: int = block.shape[0]\n",
    "    cols: int = block.shape[1]\n",
    "    dep: int = block.shape[2]\n",
    "    x_centroid: float = 0.0\n",
    "    y_centroid: float = 0.0\n",
    "    z_centroid: float = 0.0\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            for k in range(dep):\n",
    "                x_centroid += i * block[i, j, k]\n",
    "                y_centroid += j * block[i, j, k]\n",
    "                z_centroid += k * block[i, j, k]\n",
    "    total: float64 = np.sum(a=block)\n",
    "    return x_centroid / total, y_centroid / total, z_centroid / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24340826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_with_centroid(\n",
    "    image: NDArray[float64],\n",
    "    block_size: int = 50,\n",
    ") -> NDArray[float64]:\n",
    "    features: NDArray[float64] = np.zeros(\n",
    "        shape=(100 // block_size, 100 // block_size, 3)\n",
    "    )\n",
    "    for i in range(0, 100, block_size):\n",
    "        for j in range(0, 100, block_size):\n",
    "            block: NDArray[float64] = image[i : i + block_size, j : j + block_size]\n",
    "            centroid: tuple[float64, float64, float64] = calculate_centroid(block=block)\n",
    "            x_centroid: float64 = centroid[0]\n",
    "            y_centroid: float64 = centroid[1]\n",
    "            z_centroid: float64 = centroid[2]\n",
    "            features[int(i / block_size), int(j / block_size), 0] = x_centroid\n",
    "            features[int(i / block_size), int(j / block_size), 1] = y_centroid\n",
    "            features[int(i / block_size), int(j / block_size), 2] = z_centroid\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434c1927",
   "metadata": {},
   "outputs": [],
   "source": [
    "split: list[NDArray] = train_test_split(\n",
    "    images_array,\n",
    "    images_label,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    ")\n",
    "x_train: NDArray[float64] = split[0]\n",
    "x_test: NDArray[float64] = split[1]\n",
    "y_train: NDArray[uint] = split[2]\n",
    "y_test: NDArray[uint] = split[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadaba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"train input shape: {x_train.shape}, with type: {x_train.dtype}\")\n",
    "print(f\"train output shape: {y_train.shape}, with type: {y_train.dtype}\")\n",
    "print(f\"test input shape: {x_test.shape}, with type: {x_test.dtype}\")\n",
    "print(f\"test output shape: {y_test.shape}, with type: {y_test.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3807831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "train_features_with_centroid: NDArray[float64] = np.nan_to_num(\n",
    "    x=np.array(\n",
    "        object=[extract_features_with_centroid(image=image) for image in x_train]\n",
    "    )\n",
    ")\n",
    "\n",
    "test_features_with_centroid: NDArray[float64] = np.nan_to_num(\n",
    "    x=np.array(object=[extract_features_with_centroid(image=image) for image in x_test])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7163630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_with_centroid.shape, test_features_with_centroid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d3287",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_with_centroid: NDArray[float64] = train_features_with_centroid.reshape(\n",
    "    train_features_with_centroid.shape[0], -1\n",
    ")\n",
    "\n",
    "test_features_with_centroid: NDArray[float64] = test_features_with_centroid.reshape(\n",
    "    test_features_with_centroid.shape[0], -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b9ec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_with_centroid.shape, test_features_with_centroid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a0c96",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7c3106",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr: float = 0.01,\n",
    "        num_iter: int = 1000,\n",
    "        verbose: bool = False,\n",
    "    ) -> None:\n",
    "        self.lr: float = lr\n",
    "        self.num_iter: int = num_iter\n",
    "        self.verbose: bool = verbose\n",
    "        self.weights: NDArray[float64] = np.array(object=[])\n",
    "        self.bias: float64 = float64(0.0)\n",
    "        self.x: NDArray[float64] = np.array(object=[])\n",
    "        self.y: NDArray[uint] = np.array(object=[])\n",
    "        self.classes_ = None\n",
    "        self.m: int = 0\n",
    "        self.n: int = 0\n",
    "        self.losses: list[float64] = []\n",
    "        self.accuracies: list[float64] = []\n",
    "\n",
    "    def gradient_descent(self) -> None:\n",
    "        y_hat: NDArray[float64] = self.predict(x=self.x)\n",
    "        dw: NDArray[float64] = (1.0 / self.m) * np.dot(a=self.x.T, b=(y_hat - self.y))\n",
    "        db: float64 = (1.0 / self.m) * np.sum(a=y_hat - self.y)\n",
    "        self.weights -= self.lr * dw\n",
    "        self.bias -= self.lr * db\n",
    "\n",
    "    def predict(self, x: NDArray[float64]) -> NDArray[float64]:\n",
    "        z: NDArray[float64] = np.dot(a=x, b=self.weights) + self.bias\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def plot(self) -> None:\n",
    "        plt.plot(self.losses)\n",
    "        plt.plot(self.accuracies)\n",
    "        plt.xlabel(xlabel=\"Number of iterations\")\n",
    "        plt.ylabel(ylabel=\"Loss\")\n",
    "        plt.legend([\"Loss\", \"Accuracy\"])\n",
    "        plt.show()\n",
    "\n",
    "    def loss(self) -> None:\n",
    "        y_hat: NDArray[float64] = self.predict(x=self.x)\n",
    "        self.losses.append(\n",
    "            -np.mean(\n",
    "                a=self.y * np.log(y_hat + float_info.min)\n",
    "                + (1 - self.y) * np.log(1 - y_hat + float_info.min)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def accuracy(self) -> None:\n",
    "        y_hat: NDArray[float64] = self.predict(x=self.x)\n",
    "        acc: float64 = np.mean(y_hat.round() == self.y)\n",
    "        self.accuracies.append(acc)\n",
    "\n",
    "    def fit(self, x: NDArray[float64], y: NDArray[uint]) -> None:\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        best_loss: float64 = float64(float_info.max)\n",
    "        patience: int = 5\n",
    "        self.m = x.shape[0]\n",
    "        self.n = x.shape[1]\n",
    "        self.weights = np.random.rand(self.n)\n",
    "        self.bias = float64(np.random.rand())\n",
    "        for _ in range(self.num_iter):\n",
    "            self.gradient_descent()\n",
    "            self.loss()\n",
    "            self.accuracy()\n",
    "            if self.losses[-1] < best_loss:\n",
    "                best_loss = self.losses[-1]\n",
    "                patience = 5\n",
    "            else:\n",
    "                patience -= 1\n",
    "                if patience == 0:\n",
    "                    break\n",
    "        if self.verbose:\n",
    "            print(f\"\\nFinal Loss: {self.losses[-1]}\")\n",
    "            print(f\"Final Accuracy: {self.accuracies[-1]}\")\n",
    "\n",
    "    def eval(self, x: NDArray[float64], y: NDArray[uint]) -> None:\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.accuracy()\n",
    "        if self.verbose:\n",
    "            y_hat: NDArray[float64] = self.predict(x=self.x)\n",
    "            print(f\"Accuracy: {self.accuracies[-1]}\")\n",
    "            print(f\"Loss: {self.losses[-1]}\")\n",
    "            print(f\"F1 Score: {f1_score(y_true=self.y, y_pred=y_hat.round())}\")\n",
    "            print(f\"Precision: {precision_score(y_true=self.y, y_pred=y_hat.round())}\")\n",
    "            print(f\"Recall: {recall_score(y_true=self.y, y_pred=y_hat.round())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bc3c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399fcf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(ar=y_train), np.unique(ar=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78a681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_with_centroid: NDArray[float64] = (\n",
    "    train_features_with_centroid - train_features_with_centroid.mean()\n",
    ") / train_features_with_centroid.std()\n",
    "\n",
    "test_features_with_centroid: NDArray[float64] = (\n",
    "    test_features_with_centroid - test_features_with_centroid.mean()\n",
    ") / test_features_with_centroid.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbda563",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_features_with_centroid, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8900f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fc71fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval(x=train_features_with_centroid, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaaf120",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval(x=test_features_with_centroid, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        y_true=y_test,\n",
    "        y_pred=model.predict(x=test_features_with_centroid).round(),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322fcd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea6deff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e678e7",
   "metadata": {},
   "source": [
    "# Particle Swarm Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b51fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tries: list[NDArray[float64]] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dec7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self, bounds: list[tuple[int | float, int | float]]) -> None:\n",
    "        self.position: NDArray[float64] = np.array(\n",
    "            object=[np.random.uniform(low=b[0], high=b[1]) for b in bounds]\n",
    "        )\n",
    "        self.velocity: NDArray[float64] = np.array(\n",
    "            object=[\n",
    "                np.random.uniform(low=-abs(b[1] - b[0]), high=abs(b[1] - b[0]))\n",
    "                for b in bounds\n",
    "            ]\n",
    "        )\n",
    "        self.best_position: NDArray[float64] = self.position.copy()\n",
    "        self.best_fitness: float = float_info.max\n",
    "        self.fitness: float = float_info.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4bb35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_velocity(\n",
    "    particle: Particle,\n",
    "    global_best_position: NDArray[float64],\n",
    "    w: float = 0.5,\n",
    "    c1: float = 1.0,\n",
    "    c2: float = 2.0,\n",
    ") -> None:\n",
    "    inertia: NDArray[float64] = w * particle.velocity\n",
    "    cognitive: NDArray[float64] = (\n",
    "        c1 * np.random.random() * (particle.best_position - particle.position)\n",
    "    )\n",
    "    social: NDArray[float64] = (\n",
    "        c2 * np.random.random() * (global_best_position - particle.position)\n",
    "    )\n",
    "    particle.velocity = inertia + cognitive + social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245e98d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_position(\n",
    "    particle: Particle,\n",
    "    bounds: list[tuple[int | float, int | float]],\n",
    ") -> None:\n",
    "    particle.position += particle.velocity\n",
    "    # Ensure the particle's position is within the bounds\n",
    "    for i in range(len(bounds)):\n",
    "        if particle.position[i] < bounds[i][0]:\n",
    "            particle.position[i] = bounds[i][0]\n",
    "        elif particle.position[i] > bounds[i][1]:\n",
    "            particle.position[i] = bounds[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1d1037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(subset: NDArray[float64]) -> float:\n",
    "    tries.append(subset)\n",
    "    print(f\"\\tTrying Subset: {round(number=subset[0])}, LR: {subset[1]}\")\n",
    "    X_train_subset: NDArray[float64] = train_features_with_centroid[\n",
    "        :, : round(number=subset[0])\n",
    "    ]\n",
    "    X_test_subset: NDArray[float64] = test_features_with_centroid[\n",
    "        :, : round(number=subset[0])\n",
    "    ]\n",
    "    model = LogisticRegression(lr=subset[1])\n",
    "    model.fit(x=X_train_subset, y=y_train)\n",
    "    model.eval(x=X_test_subset, y=y_test)\n",
    "    y_hat: NDArray[float64] = model.predict(x=X_test_subset)\n",
    "    return -float(f1_score(y_true=y_test, y_pred=y_hat.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a893d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pso(\n",
    "    objective_function: Callable[[NDArray[float64]], float],\n",
    "    bounds: list[tuple[int | float, int | float]],\n",
    "    num_particles: int,\n",
    "    max_iter: int,\n",
    ") -> tuple[NDArray[float64], float]:\n",
    "    swarm: list[Particle] = [Particle(bounds=bounds) for _ in range(num_particles)]\n",
    "    global_best_position = np.zeros(shape=len(bounds))\n",
    "    global_best_fitness: float = float_info.max\n",
    "    for iteration in range(max_iter):\n",
    "        for particle in swarm:\n",
    "            particle.fitness = objective_function(particle.position)\n",
    "            if particle.fitness < particle.best_fitness:\n",
    "                particle.best_fitness = particle.fitness\n",
    "                particle.best_position = particle.position.copy()\n",
    "            if particle.fitness < global_best_fitness:\n",
    "                global_best_fitness = particle.fitness\n",
    "                global_best_position: NDArray[float64] = particle.position.copy()\n",
    "        for particle in swarm:\n",
    "            update_velocity(\n",
    "                particle=particle, global_best_position=global_best_position\n",
    "            )\n",
    "            update_position(particle=particle, bounds=bounds)\n",
    "        print(f\"Iteration {iteration + 1}/{max_iter}\")\n",
    "        print(f\"Global Best Fitness: {-global_best_fitness}\")\n",
    "        print(f\"Global Best Position: {global_best_position}\")\n",
    "    return global_best_position, -global_best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da53e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best: tuple[NDArray[float64], float] = pso(\n",
    "    objective_function=objective_function,\n",
    "    bounds=[(2, 12), (0.01, 0.99)],\n",
    "    num_particles=100,\n",
    "    max_iter=100,\n",
    ")\n",
    "best_position: NDArray[float64] = best[0]\n",
    "best_fitness: float = best[1]\n",
    "\n",
    "print(\"Best position:\", best_position)\n",
    "print(\"Best fitness:\", best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec65b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tries: NDArray[float64] = np.array(object=tries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "tries[:, 0] = np.round(a=tries[:, 0])\n",
    "subsets: NDArray[float64] = np.unique(ar=tries[:, 0])\n",
    "lrs: NDArray[float64] = np.unique(ar=tries[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f20f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets, lrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a1c1bd",
   "metadata": {},
   "source": [
    "# After Particle Swarm Optimization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(verbose=True, lr=best_position[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23829a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x=train_features_with_centroid[:, : round(number=best_position[0])],\n",
    "    y=y_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04d4241",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval(\n",
    "    x=train_features_with_centroid[:, : round(number=best_position[0])],\n",
    "    y=y_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85520e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval(\n",
    "    x=test_features_with_centroid[:, : round(number=best_position[0])],\n",
    "    y=y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db44546",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        y_true=y_test,\n",
    "        y_pred=model.predict(\n",
    "            x=test_features_with_centroid[:, : round(number=best_position[0])]\n",
    "        ).round(),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d4e2f5",
   "metadata": {},
   "source": [
    "# Feature Reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82db092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA:\n",
    "    def __init__(self) -> None:\n",
    "        self.w: NDArray[float64] = np.array(object=[])\n",
    "\n",
    "    def fit(self, X: NDArray[float64], y: NDArray[uint]) -> None:\n",
    "        m0 = np.mean(a=X[y == 0], axis=0)\n",
    "        m1 = np.mean(a=X[y == 1], axis=0)\n",
    "        S0 = np.dot(a=(X[y == 0] - m0).T, b=(X[y == 0] - m0))\n",
    "        S1 = np.dot(a=(X[y == 1] - m1).T, b=(X[y == 1] - m1))\n",
    "        Sw = S0 + S1\n",
    "        self.w = np.dot(a=np.linalg.inv(Sw), b=(m1 - m0))\n",
    "\n",
    "    def transform(self, X: NDArray[float64]) -> NDArray[float64]:\n",
    "        result: NDArray[float64] = np.dot(a=X, b=self.w)\n",
    "        return (result - result.mean()) / result.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f70ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cf04c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.fit(\n",
    "    X=train_features_with_centroid[:, : round(number=best_position[0])],\n",
    "    y=y_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30388c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_with_centroid: NDArray[float64] = lda.transform(\n",
    "    X=train_features_with_centroid[:, : round(number=best_position[0])]\n",
    ")\n",
    "test_features_with_centroid: NDArray[float64] = lda.transform(\n",
    "    X=test_features_with_centroid[:, : round(number=best_position[0])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc3b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_with_centroid: NDArray[float64] = train_features_with_centroid.reshape(\n",
    "    -1, 1\n",
    ")\n",
    "test_features_with_centroid: NDArray[float64] = test_features_with_centroid.reshape(\n",
    "    -1, 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf56920",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_with_centroid.shape, test_features_with_centroid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1b4c8b",
   "metadata": {},
   "source": [
    "# After Feature Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c78b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(verbose=True, lr=best_position[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c325d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=train_features_with_centroid, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965d4d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b68262",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval(x=train_features_with_centroid, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6757671",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval(x=test_features_with_centroid, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a3f35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    classification_report(\n",
    "        y_true=y_test,\n",
    "        y_pred=model.predict(x=test_features_with_centroid).round(),\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Covid_w/wo_pneumonia",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1057171,
     "sourceId": 1778086,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1277.842172,
   "end_time": "2025-05-26T14:42:58.763134",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-26T14:21:40.920962",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {},
   "source": [
    "<a href=\"https://www.kaggle.com/code/mh0386/logistic-regression-with-least-squares-technique?scriptVersionId=244761054\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e44e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import float_info\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from pandas import get_dummies\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a182cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf1f89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05b586",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d0627",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10918ea",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4392aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(\n",
    "        self,\n",
    "        lr=0.1,\n",
    "        num_iter=1_000_000,\n",
    "        verbose=False,\n",
    "        multi_class=False,\n",
    "        least_squares=False,\n",
    "    ) -> None:\n",
    "        self.lr = lr\n",
    "        self.num_iter = num_iter\n",
    "        self.verbose = verbose\n",
    "        self.least_squares = least_squares\n",
    "        self.multi_class = multi_class\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.classes_ = None\n",
    "        self.m = None\n",
    "        self.n = None\n",
    "        self.losses = []\n",
    "        self.accuracies = []\n",
    "\n",
    "    def softmax(self, x: np.ndarray) -> np.ndarray:\n",
    "        e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        return e_x / e_x.sum(axis=1, keepdims=True)\n",
    "\n",
    "    def gradient_descent(self, x: np.ndarray, y: np.ndarray) -> None:\n",
    "        y_hat = self.predict(x)\n",
    "        dw = (1 / self.m) * np.dot(x.T, (y_hat - y))\n",
    "        db = (1 / self.m) * np.sum(y_hat - y)\n",
    "        self.weights -= self.lr * dw\n",
    "        self.bias -= self.lr * db\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        if self.least_squares:\n",
    "            x = np.c_[np.ones(x.shape[0]), x]\n",
    "            return np.dot(x, self.weights)\n",
    "        z = np.dot(x, self.weights) + self.bias\n",
    "        predication = 1.0 / (1.0 + np.exp(-z))\n",
    "        return self.softmax(predication) if self.multi_class else predication\n",
    "\n",
    "    def plot(self) -> None:\n",
    "        pyplot.plot(self.losses)\n",
    "        pyplot.plot(self.accuracies)\n",
    "        pyplot.xlabel(\"Number of iterations\")\n",
    "        pyplot.ylabel(\"Loss\")\n",
    "        pyplot.legend([\"Loss\", \"Accuracy\"])\n",
    "        pyplot.show()\n",
    "\n",
    "    def loss(self, x: np.ndarray, y: np.ndarray) -> float:\n",
    "        y_hat = self.predict(x)\n",
    "        self.losses.append(\n",
    "            -np.mean(\n",
    "                y * np.log(y_hat + float_info.min)\n",
    "                + (1 - y) * np.log(1 - y_hat + float_info.min)\n",
    "            )\n",
    "        )\n",
    "        return self.losses[-1]\n",
    "\n",
    "    def accuracy(self, x: np.ndarray, y: np.ndarray) -> None:\n",
    "        y_hat = self.predict(x)\n",
    "        acc = (\n",
    "            np.mean(y_hat.argmax(axis=1) == y.argmax(axis=1))\n",
    "            if self.multi_class\n",
    "            else np.mean(y_hat.round() == y)\n",
    "        )\n",
    "        self.accuracies.append(acc)\n",
    "\n",
    "    def fit(self, x: np.ndarray, y: np.ndarray) -> None:\n",
    "        if self.least_squares:\n",
    "            self.least_squares_technique(x, y)\n",
    "            return\n",
    "        best_loss = float_info.max\n",
    "        patience = 10\n",
    "        self.m, self.n = x.shape\n",
    "        if self.multi_class:\n",
    "            self.classes_ = np.unique(y)\n",
    "            y = get_dummies(y).to_numpy()\n",
    "            self.weights = (\n",
    "                np.random.rand(self.n, len(self.classes_))\n",
    "                if self.weights is None\n",
    "                else self.weights\n",
    "            )\n",
    "            self.bias = (\n",
    "                np.random.rand(len(self.classes_)) if self.bias is None else self.bias\n",
    "            )\n",
    "        else:\n",
    "            self.weights = (\n",
    "                np.random.rand(self.n) if self.weights is None else self.weights\n",
    "            )\n",
    "            self.bias = np.random.rand() if self.bias is None else self.bias\n",
    "        for _ in range(self.num_iter):\n",
    "            self.gradient_descent(x, y)\n",
    "            self.loss(x, y)\n",
    "            self.accuracy(x, y)\n",
    "\n",
    "            if self.losses[-1] < best_loss:\n",
    "                best_loss = self.losses[-1]\n",
    "                patience = 10\n",
    "            else:\n",
    "                patience -= 1\n",
    "                if patience == 0:\n",
    "                    break\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f\"\\tLoss: {self.losses[-1]}\")\n",
    "                print(f\"\\tAccuracy: {self.accuracies[-1]}\")\n",
    "        print(f\"\\nFinal Loss: {self.losses[-1]}\")\n",
    "        print(f\"Final Accuracy: {self.accuracies[-1]}\")\n",
    "\n",
    "    def eval(self, x: np.ndarray, y: np.ndarray) -> None:\n",
    "        if self.multi_class:\n",
    "            y = get_dummies(y).to_numpy()\n",
    "        self.accuracy(x, y)\n",
    "        print(f\"Accuracy: {self.accuracies[-1]}\")\n",
    "\n",
    "    def least_squares_technique(self, x: np.ndarray, y: np.ndarray) -> None:\n",
    "        x = np.c_[np.ones(x.shape[0]), x]\n",
    "        self.weights = np.dot(np.dot(np.linalg.inv(np.dot(x.T, x)), x.T), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cdef57",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2c58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd5c55d",
   "metadata": {},
   "source": [
    "# With Least Squares Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef10b9",
   "metadata": {},
   "source": [
    "# Group samples of class 2 and class 3 together to form new class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1574bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.where(y == 2, 1, y)\n",
    "\n",
    "X_train_class1, X_test_class1, Y_train_class1, Y_test_class1 = train_test_split(\n",
    "    x[Y_train == 0], Y_train[Y_train == 0], test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_class2, X_test_class2, Y_train_class2, Y_test_class2 = train_test_split(\n",
    "    x[Y_train == 1], Y_train[Y_train == 1], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train = np.concatenate((X_train_class1, X_train_class2), axis=0)\n",
    "X_test = np.concatenate((X_test_class1, X_test_class2), axis=0)\n",
    "Y_train = np.concatenate((Y_train_class1, Y_train_class2), axis=0)\n",
    "Y_test = np.concatenate((Y_test_class1, Y_test_class2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b9f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    np.unique(Y_train),\n",
    "    X_train_class1.shape,\n",
    "    X_test_class1.shape,\n",
    "    X_train_class2.shape,\n",
    "    X_test_class2.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1752d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(least_squares=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2645a579",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437fe1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0653921",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3952a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, Y_pred.round())\n",
    "pyplot.imshow(\n",
    "    confusion_matrix(Y_test, Y_pred.round()), cmap=\"binary\", interpolation=\"None\"\n",
    ")\n",
    "pyplot.title(\"Confusion Matrix\")\n",
    "pyplot.xlabel(\"Predicted\")\n",
    "pyplot.ylabel(\"Actual\")\n",
    "pyplot.xticks([0, 1])\n",
    "pyplot.yticks([0, 1])\n",
    "pyplot.colorbar()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8059441",
   "metadata": {},
   "source": [
    "# Group samples of class 1 and class 3 together to form new class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907319ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.where(y == 2, 0, y)\n",
    "\n",
    "X_train_class1, X_test_class1, Y_train_class1, Y_test_class1 = train_test_split(\n",
    "    x[Y_train == 0], Y_train[Y_train == 0], test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_class2, X_test_class2, Y_train_class2, Y_test_class2 = train_test_split(\n",
    "    x[Y_train == 1], Y_train[Y_train == 1], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train = np.concatenate((X_train_class1, X_train_class2), axis=0)\n",
    "X_test = np.concatenate((X_test_class1, X_test_class2), axis=0)\n",
    "Y_train = np.concatenate((Y_train_class1, Y_train_class2), axis=0)\n",
    "Y_test = np.concatenate((Y_test_class1, Y_test_class2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcafcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    np.unique(Y_train),\n",
    "    X_train_class1.shape,\n",
    "    X_test_class1.shape,\n",
    "    X_train_class2.shape,\n",
    "    X_test_class2.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f8a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(least_squares=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3e3e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1279e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc6ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767ebe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, Y_pred.round())\n",
    "pyplot.imshow(\n",
    "    confusion_matrix(Y_test, Y_pred.round()), cmap=\"binary\", interpolation=\"None\"\n",
    ")\n",
    "pyplot.title(\"Confusion Matrix\")\n",
    "pyplot.xlabel(\"Predicted\")\n",
    "pyplot.ylabel(\"Actual\")\n",
    "pyplot.xticks([0, 1])\n",
    "pyplot.yticks([0, 1])\n",
    "pyplot.colorbar()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836ac95b",
   "metadata": {},
   "source": [
    "# Group samples of class 1 and class 2 together to form new class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f0ff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.where(y == 1, 0, y)\n",
    "Y_train = np.where(y == 2, 1, Y_train)\n",
    "\n",
    "X_train_class1, X_test_class1, Y_train_class1, Y_test_class1 = train_test_split(\n",
    "    x[Y_train == 0], Y_train[Y_train == 0], test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_class2, X_test_class2, Y_train_class2, Y_test_class2 = train_test_split(\n",
    "    x[Y_train == 1], Y_train[Y_train == 1], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train = np.concatenate((X_train_class1, X_train_class2), axis=0)\n",
    "X_test = np.concatenate((X_test_class1, X_test_class2), axis=0)\n",
    "Y_train = np.concatenate((Y_train_class1, Y_train_class2), axis=0)\n",
    "Y_test = np.concatenate((Y_test_class1, Y_test_class2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f14c882",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    np.unique(Y_train),\n",
    "    X_train_class1.shape,\n",
    "    X_test_class1.shape,\n",
    "    X_train_class2.shape,\n",
    "    X_test_class2.shape,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2426b532",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(least_squares=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f08ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a95a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d4de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4eaf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, Y_pred.round())\n",
    "pyplot.imshow(confusion_matrix(Y_test, Y_pred.round()), cmap=\"binary\")\n",
    "pyplot.title(\"Confusion Matrix\")\n",
    "pyplot.xlabel(\"Predicted\")\n",
    "pyplot.ylabel(\"Actual\")\n",
    "pyplot.xticks([0, 1])\n",
    "pyplot.yticks([0, 1])\n",
    "pyplot.colorbar()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da4123",
   "metadata": {},
   "source": [
    "# With Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e52888",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5afea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(multi_class=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126b6719",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train - x_train.mean()) / x_train.std()\n",
    "x_test = (x_test - x_test.mean()) / x_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83ee99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e1e601",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56d9df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808aca57",
   "metadata": {},
   "source": [
    "# Group samples of class 2 and class 3 together to form new class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eb9433",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.where(y == 2, 1, y)\n",
    "\n",
    "X_train_class1, X_test_class1, Y_train_class1, Y_test_class1 = train_test_split(\n",
    "    x[Y_train == 0], Y_train[Y_train == 0], test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_class2, X_test_class2, Y_train_class2, Y_test_class2 = train_test_split(\n",
    "    x[Y_train == 1], Y_train[Y_train == 1], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train = np.concatenate((X_train_class1, X_train_class2), axis=0)\n",
    "X_test = np.concatenate((X_test_class1, X_test_class2), axis=0)\n",
    "Y_train = np.concatenate((Y_train_class1, Y_train_class2), axis=0)\n",
    "Y_test = np.concatenate((Y_test_class1, Y_test_class2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c273fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d85948",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81cbf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e817ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d06a779",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f81e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, Y_pred.round())\n",
    "pyplot.imshow(\n",
    "    confusion_matrix(Y_test, Y_pred.round()), cmap=\"binary\", interpolation=\"None\"\n",
    ")\n",
    "pyplot.title(\"Confusion Matrix\")\n",
    "pyplot.xlabel(\"Predicted\")\n",
    "pyplot.ylabel(\"Actual\")\n",
    "pyplot.xticks([0, 1])\n",
    "pyplot.yticks([0, 1])\n",
    "pyplot.colorbar()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096c3ea7",
   "metadata": {},
   "source": [
    "# Group samples of class 1 and class 3 together to form new class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07db3774",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.where(y == 2, 0, y)\n",
    "\n",
    "X_train_class1, X_test_class1, Y_train_class1, Y_test_class1 = train_test_split(\n",
    "    x[Y_train == 0], Y_train[Y_train == 0], test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_class2, X_test_class2, Y_train_class2, Y_test_class2 = train_test_split(\n",
    "    x[Y_train == 1], Y_train[Y_train == 1], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train = np.concatenate((X_train_class1, X_train_class2), axis=0)\n",
    "X_test = np.concatenate((X_test_class1, X_test_class2), axis=0)\n",
    "Y_train = np.concatenate((Y_train_class1, Y_train_class2), axis=0)\n",
    "Y_test = np.concatenate((Y_test_class1, Y_test_class2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67975654",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b28a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb4dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c502139",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c92ef8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa146cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, Y_pred.round())\n",
    "pyplot.imshow(\n",
    "    confusion_matrix(Y_test, Y_pred.round()), cmap=\"binary\", interpolation=\"None\"\n",
    ")\n",
    "pyplot.title(\"Confusion Matrix\")\n",
    "pyplot.xlabel(\"Predicted\")\n",
    "pyplot.ylabel(\"Actual\")\n",
    "pyplot.xticks([0, 1])\n",
    "pyplot.yticks([0, 1])\n",
    "pyplot.colorbar()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7c4dd",
   "metadata": {},
   "source": [
    "# Group samples of class 1 and class 2 together to form new class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400ea0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.where(y == 1, 0, y)\n",
    "Y_train = np.where(y == 2, 1, Y_train)\n",
    "\n",
    "X_train_class1, X_test_class1, Y_train_class1, Y_test_class1 = train_test_split(\n",
    "    x[Y_train == 0], Y_train[Y_train == 0], test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_class2, X_test_class2, Y_train_class2, Y_test_class2 = train_test_split(\n",
    "    x[Y_train == 1], Y_train[Y_train == 1], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train = np.concatenate((X_train_class1, X_train_class2), axis=0)\n",
    "X_test = np.concatenate((X_test_class1, X_test_class2), axis=0)\n",
    "Y_train = np.concatenate((Y_train_class1, Y_train_class2), axis=0)\n",
    "Y_test = np.concatenate((Y_test_class1, Y_test_class2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88866d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df12e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc07da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ddd96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c48971",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d654fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, Y_pred.round())\n",
    "pyplot.imshow(\n",
    "    confusion_matrix(Y_test, Y_pred.round()), cmap=\"binary\", interpolation=\"None\"\n",
    ")\n",
    "pyplot.title(\"Confusion Matrix\")\n",
    "pyplot.xlabel(\"Predicted\")\n",
    "pyplot.ylabel(\"Actual\")\n",
    "pyplot.xticks([0, 1])\n",
    "pyplot.yticks([0, 1])\n",
    "pyplot.colorbar()\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 247.355821,
   "end_time": "2025-06-10T20:13:19.086714",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-10T20:09:11.730893",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

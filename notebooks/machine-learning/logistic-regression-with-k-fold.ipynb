{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c518ba691b1040f8",
   "metadata": {},
   "source": [
    "<a href=\"https://www.kaggle.com/code/mh0386/logistic-regression-with-k-fold?scriptVersionId=244761557\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb13b24",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77ee81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.pyplot import plot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a0a370",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1964a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    return (x - np.mean(x)) / np.std(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb522d6",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b637c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5736e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, W, B):\n",
    "    pred = sigmoid(np.dot(X, W) + B)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd94a63",
   "metadata": {},
   "source": [
    "# Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3265b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y, y_hat):\n",
    "    return np.mean(\n",
    "        -y * np.log(y_hat + sys.float_info.min)\n",
    "        - (1 - y) * np.log(1 - y_hat + sys.float_info.min)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe494f48",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10132158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, learning_rate, epochs):\n",
    "    W = np.random.rand(X.shape[1], y.shape[1])\n",
    "    B = np.random.random()\n",
    "    costs = np.array([])\n",
    "    for i in range(epochs):\n",
    "        y_hat = predict(X, W, B)\n",
    "        dW = np.dot(X.T, (y_hat - y)) / len(X)\n",
    "        db = np.mean(y_hat - y)\n",
    "        W -= learning_rate * dW\n",
    "        B -= learning_rate * db\n",
    "        if i % 100 == 0:\n",
    "            costValue: float = cost(y, y_hat)\n",
    "            costs = np.append(costs, costValue)\n",
    "            print(f\"Cost at epoch {i}: {costValue}\")\n",
    "    return W, B, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fcdc7d",
   "metadata": {},
   "source": [
    "# Train with L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf291e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_L1(X, y, learning_rate, epochs, Lambda):\n",
    "    W = np.random.random(X.shape[1])\n",
    "    B = np.random.random()\n",
    "    costs = np.array([])\n",
    "    for i in range(epochs):\n",
    "        y_hat = predict(X, W, B)\n",
    "        dW = np.dot(X.T, (y_hat - y)) / len(X)\n",
    "        db = np.mean(y_hat - y)\n",
    "        W -= learning_rate * (dW + Lambda * np.sign(W))\n",
    "        B -= learning_rate * db\n",
    "        if i % 100 == 0:\n",
    "            costValue: float = cost(y, y_hat)\n",
    "            costs = np.append(costs, costValue)\n",
    "            print(f\"Cost at epoch {i}: {costValue}\")\n",
    "    return W, B, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6a0732",
   "metadata": {},
   "source": [
    "# Mini_Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a8b7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mini_batch(X, y, learning_rate, epochs, batch_size):\n",
    "    W = np.random.random(X.shape[1])\n",
    "    B = np.random.random()\n",
    "    costs = np.array([])\n",
    "    for i in range(epochs):\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            X_batch = X[j : j + batch_size]\n",
    "            y_batch = y[j : j + batch_size]\n",
    "            y_hat = predict(X_batch, W, B)\n",
    "            dW = np.dot(X_batch.T, (y_hat - y_batch)) / len(X_batch)\n",
    "            db = np.mean(y_hat - y_batch)\n",
    "            W -= learning_rate * dW\n",
    "            B -= learning_rate * db\n",
    "            if i % 100 == 0:\n",
    "                costValue: float = cost(y, y_hat)\n",
    "                costs = np.append(costs, costValue)\n",
    "                print(f\"Cost at epoch {i}: {costValue}\")\n",
    "    return W, B, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a900cdb",
   "metadata": {},
   "source": [
    "# RMS Prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb47657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rms_prop(X, y, learning_rate, epochs, beta, epsilon=sys.float_info.min):\n",
    "    W = np.random.random(X.shape[1])\n",
    "    B = np.random.random()\n",
    "    costs = np.array([])\n",
    "    vW = np.zeros(X.shape[1])\n",
    "    vB = 0\n",
    "    for i in range(epochs):\n",
    "        y_hat = predict(X, W, B)\n",
    "        dW = np.dot(X.T, (y_hat - y)) / len(X)\n",
    "        dB = np.mean(y_hat - y)\n",
    "        vW = beta * vW + (1 - beta) * dW**2\n",
    "        vB = beta * vB + (1 - beta) * dB**2\n",
    "        W -= learning_rate * dW / (np.sqrt(vW) + epsilon)\n",
    "        B -= learning_rate * dB / (np.sqrt(vB) + epsilon)\n",
    "        if i % 100 == 0:\n",
    "            costValue: float = cost(y, y_hat)\n",
    "            costs = np.append(costs, costValue)\n",
    "            print(f\"Cost at epoch {i}: {costValue}\")\n",
    "    return W, B, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f478f",
   "metadata": {},
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ebd525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_adam(X, y, learning_rate, epochs, beta1, beta2, epsilon=sys.float_info.min):\n",
    "    W = np.random.random(X.shape[1])\n",
    "    B = np.random.random()\n",
    "    costs = np.array([])\n",
    "    vW = np.zeros(X.shape[1])\n",
    "    vB = 0\n",
    "    sW = np.zeros(X.shape[1])\n",
    "    sB = 0\n",
    "    for i in range(epochs):\n",
    "        y_hat = predict(X, W, B)\n",
    "        dW = np.dot(X.T, (y_hat - y)) / len(X)\n",
    "        dB = np.mean(y_hat - y)\n",
    "        vW = beta1 * vW + (1 - beta1) * dW\n",
    "        vB = beta1 * vB + (1 - beta1) * dB\n",
    "        sW = beta2 * sW + (1 - beta2) * dW**2\n",
    "        sB = beta2 * sB + (1 - beta2) * dB**2\n",
    "        vW_corrected = vW / (1 - beta1 ** (i + 1))\n",
    "        vB_corrected = vB / (1 - beta1 ** (i + 1))\n",
    "        sW_corrected = sW / (1 - beta2 ** (i + 1))\n",
    "        sB_corrected = sB / (1 - beta2 ** (i + 1))\n",
    "        W -= learning_rate * vW_corrected / (np.sqrt(sW_corrected) + epsilon)\n",
    "        B -= learning_rate * vB_corrected / (np.sqrt(sB_corrected) + epsilon)\n",
    "        if i % 100 == 0:\n",
    "            costValue: float = cost(y, y_hat)\n",
    "            costs = np.append(costs, costValue)\n",
    "            print(f\"Cost at epoch {i}: {costValue}\")\n",
    "    return W, B, costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b38d0f",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce5e518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X, y, W, b):\n",
    "    y_hat = predict(X, W, b)\n",
    "    return accuracy(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16e808c",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42784d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    return np.mean(y == y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aa7197",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fc9f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSet, testSet = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a2d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = trainSet[0].astype(\"float32\")\n",
    "yTrain = trainSet[1].astype(\"int32\")\n",
    "\n",
    "xTest = testSet[0].astype(\"float32\")\n",
    "yTest = testSet[1].astype(\"int32\")\n",
    "\n",
    "xTrain = xTrain.reshape(xTrain.shape[0], -1)\n",
    "xTest = xTest.reshape(xTest.shape[0], -1)\n",
    "\n",
    "xTrain = standardize(xTrain)\n",
    "xTest = standardize(xTest)\n",
    "\n",
    "p1 = np.random.permutation(len(xTrain))\n",
    "p2 = np.random.permutation(len(xTest))\n",
    "\n",
    "xTrain = xTrain[p1]\n",
    "yTrain = yTrain[p1]\n",
    "\n",
    "xTest = xTest[p2]\n",
    "yTest = yTest[p2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69215e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6471d6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5135fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain = pd.get_dummies(yTrain)\n",
    "yTrain = yTrain.astype(\"int32\")\n",
    "yTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab9f1b",
   "metadata": {},
   "source": [
    "# K-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27617a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_cross_validation(X, y, K, lr, epochs):\n",
    "    fold_size = len(X) // K\n",
    "    accuracies = []\n",
    "    for i in range(K):\n",
    "        # Divide the data into training and testing sets\n",
    "        X_train = np.concatenate([X[: i * fold_size], X[(i + 1) * fold_size :]])\n",
    "        Y_train = np.concatenate([y[: i * fold_size], y[(i + 1) * fold_size :]])\n",
    "        x_valid = X[i * fold_size : (i + 1) * fold_size]\n",
    "        y_valid = y[i * fold_size : (i + 1) * fold_size]\n",
    "        # Train the model\n",
    "        print(f\"\\nTraining at Iteration {i + 1} of {K}\")\n",
    "        w, b, Costs = train(X_train, Y_train, lr, epochs)\n",
    "        # Test the model\n",
    "        print(f\"\\nTesting at Iteration {i + 1} of {K}\")\n",
    "        acc = test(x_valid, y_valid, w, b)\n",
    "        print(f\"Accuracy at Iteration {i + 1} of {K}: {acc}\")\n",
    "        accuracies.append(acc)\n",
    "    return np.mean(accuracies), Costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e488a554",
   "metadata": {},
   "source": [
    "# Running Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ed1aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "iterations = 1000\n",
    "LRs = [0.1, 0.01, 0.001, 0.0001]\n",
    "for lr in LRs:\n",
    "    print(f\"K-Fold Cross Validation with {k} Folds and eta {lr}:\")\n",
    "    average_accuracy, c = k_fold_cross_validation(xTrain, yTrain, k, lr, iterations)\n",
    "    print(\"\\nAverage Accuracy: \", average_accuracy)\n",
    "    plt(c, label=f\"eta = {lr}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10181.809528,
   "end_time": "2025-06-10T23:04:16.756003",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-10T20:14:34.946475",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
